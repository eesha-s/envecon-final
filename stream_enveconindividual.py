# -*- coding: utf-8 -*-
"""stream_enveconindividual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O2tEWVmXtgkcOJEk3A7JL3VqcVan_f20
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit

#import seaborn as sns

"""I answered the main questions at the very end!! :)

# **DATA IMPORT**
"""

#co2 emissions per capita
co2= pd.read_csv('https://raw.githubusercontent.com/eesha-s/envecon_individual/refs/heads/main/co2_pcap_cons.csv')
co2.head()

gdp=pd.read_csv('https://raw.githubusercontent.com/eesha-s/envecon_individual/refs/heads/main/gdp_pcap.csv')
gdp.head()

energy=pd.read_csv('https://raw.githubusercontent.com/eesha-s/envecon_individual/refs/heads/main/energy_use_per_person.csv')
energy.head()

#skipped rows bc had additional headings
disasters=pd.read_csv('https://raw.githubusercontent.com/eesha-s/envecon_individual/refs/heads/main/time-series-US-cost-1980-2024.csv', skiprows=3)
disasters.head()

temperature= pd.read_csv('https://raw.githubusercontent.com/eesha-s/envecon_individual/refs/heads/main/temperature.csv',skiprows=4)
temperature.head()

"""# **DATA WRANGLING**"""

# WE FIRST NEED TO CONVERT CO2 FROM WIDE TO LONG
co2_long=pd.melt(co2, id_vars='country',var_name="Year",value_name="Emissions")
co2_long['Year'].dtype
#we want to convert year into a numeric data type
co2_long['Year']=pd.to_numeric(co2_long['Year'])
co2_long['Year'].dtype #yay!
co2_long=co2_long.rename(columns={'country': 'Country'}) #capitalized
co2_long['Label']='CO2 Emissions'
co2_long.head()

print(gdp.shape)
#now let's restructure this table again
gdp_long=pd.melt(gdp, id_vars='country',var_name="Year",value_name="GDP")
gdp_long['Year']=pd.to_numeric(gdp_long['Year'])
gdp_long=gdp_long.rename(columns={'country': 'Country'})
gdp_long['Label']='GDP Growth/Capita'
gdp_long.head()

#now we can do the same with energy use
energy_long=pd.melt(energy,id_vars='country',var_name="Year",value_name="Energy Use")
energy_long['Year']=pd.to_numeric(energy_long['Year'])
energy_long=energy_long.rename(columns={'country': 'Country'})
energy_long['Label']='Energy Use'
energy_long.head()

condition= [col for col in disasters.columns if 'Count' in col or col=='Year'] #selecting only the natural disaster count
disasters_new=disasters[condition]
disasters_new.head()
disasters_new['Country']="United States"
disasters_new["Indicator"]="Disasters"
disasters_new["Label"]="Disasters"
disasters_new=disasters_new.rename(columns={'All Disasters Count': 'Value'})
disasters_new=disasters_new[['Country','Year','Value','Indicator','Label']]
disasters_new.head()

temperature.head()

temperature["Date"]=temperature["Date"].astype(str).str[:4] #easier to index if we use a string
temperature['Date']=pd.to_numeric(temperature['Date'])
temperature=temperature.rename(columns={'Date': 'Year'}) #took the liberty of changing col name to help w joining :)
temperature["Country"]="United States"
temperature['Indicator']='Temperature'
temperature['Label']='Temperature(Farenheit)'
temperature=temperature[['Year','Country','Value','Indicator','Label']]
temperature.head()

"""## **Data Joining**"""

co2_gdp=pd.merge(co2_long,gdp_long,on=['Country','Year','Label'],how='outer')
co2_gdp_energy=pd.merge(co2_gdp,energy_long,on=['Country','Year','Label'],how='outer')
co2_gdp_energy

data_wide=co2_gdp_energy.pivot_table(index=['Country','Year','Label'], values=['Emissions', 'GDP', 'Energy Use'],aggfunc='first').reset_index()
data_wide.head()
'''
since the case study made their data wide originally i started off like that too and then converted it to long below :)
'''

data_long=pd.melt(data_wide,id_vars=['Country','Year','Label'],value_vars=['Emissions', 'GDP', 'Energy Use'],var_name='Indicator',value_name='Value')
data_long
#data_long.to_csv("data_long.csv", index=False)
#from google.colab import files
#files.download("data_long.csv")

final= pd.concat([data_long,disasters_new,temperature])
final

#pd.concat is the python version of R's bind()

final['Region']=final['Country'].apply(lambda x: 'United States' if x=='United States' or x=='USA' else 'Rest of the World')
final

#once again this is the python version of R's mutate()

final=final.dropna()
final

final.to_csv("final_dataset.csv", index=False)


"""# **Data Visualization**"""

#we first need to recreate the original co2 emissions plot
co2_plot_data = final[final['Indicator'] == 'Emissions'].copy()
co2_plot_data['Year'] = pd.to_numeric(co2_plot_data['Year'], errors='coerce')
co2_plot_data['Value'] = pd.to_numeric(co2_plot_data['Value'], errors='coerce')
co2_plot_data = co2_plot_data.dropna(subset=['Value'])
co2_plot_data = co2_plot_data.groupby('Year')['Value'].sum().reset_index()
#now just for the US data!
co2_plot_US = final[final['Indicator'] == 'Emissions'].copy()
co2_plot_US=co2_plot_US[co2_plot_US['Region']=='United States']
co2_plot_US['Year'] = pd.to_numeric(co2_plot_US['Year'], errors='coerce')
co2_plot_US['Value'] = pd.to_numeric(co2_plot_US['Value'], errors='coerce')
co2_plot_US = co2_plot_US.dropna(subset=['Value'])
co2_plot_US = co2_plot_US.groupby('Year')['Value'].sum().reset_index()
co2_plot_US.head()

#now to plot both on the same axis yay!
plt.plot(co2_plot_data['Year'], co2_plot_data['Value'])
plt.plot(co2_plot_US['Year'], co2_plot_US['Value'], color='red',label='United States')
plt.xlabel('Year')
plt.ylabel('CO2 Emissions(Metric Tons)')
plt.title('World C02 Emissions Per Year (1751-2022)')
plt.legend()
plt.grid(True)
plt.savefig('world_co2_plot.png',dpi=300) #this is for the picture summary at the very end
streamlit.pyplot(plt.gcf())  # pass the current figure object to Streamlit

plt.clf()

co2_top_ten=final[final['Indicator']=='Emissions'] #we only want emissions data
co2_top_ten['Year']=pd.to_numeric(co2_top_ten['Year'],errors='coerce')
co2_top_ten['Value']=pd.to_numeric(co2_top_ten['Value'],errors='coerce') #we need to make the values floats to actually plot them
co2_top_ten=co2_top_ten.dropna(subset=['Value'])
co2_top_ten=co2_top_ten.groupby('Country')['Value'].sum().reset_index() #sum the data for each country
co2_top_ten=co2_top_ten.sort_values(by='Value',ascending=False).head(10) #sorted in descending order then pull the top ten
co2_top_ten
co2_top_plot=final[final['Country'].isin(co2_top_ten['Country'])] #now i just take the data that has the top ten country names
co2_top_plot=co2_top_plot[co2_top_plot['Indicator']=='Emissions']
co2_top_plot['Year']=pd.to_numeric(co2_top_plot['Year'],errors='coerce')
co2_top_plot['Value']=pd.to_numeric(co2_top_plot['Value'],errors='coerce')
co2_top_plot=co2_top_plot.dropna(subset=['Value'])
co2_top_plot

top_countries=co2_top_ten['Country'].tolist() #we want the names of the top ten countries
print(top_countries)
colors=['red','orange','yellow','green','blue','indigo','violet','pink','brown','black']
for country,c in zip(top_countries,colors):
  my_data=co2_top_plot[co2_top_plot['Country']==country]
  plt.plot(my_data['Year'],my_data['Value'],color=c,label=country) #so now creating a line plot for each country with a diff color
  x=my_data['Year'].iloc[-1]
  y=my_data['Value'].iloc[-1] #taking the last data point of each line and having the label appear near it
  print(x,y)
  plt.text(x+1,y,country,fontsize=8,color=c)


plt.xlabel('Year')
plt.ylabel('CO2 Emissions(Metric Tons)')
plt.title('World C02 Emissions Per Year (1900-2022)')

tile_data=co2_top_plot[co2_top_plot['Year']>=1900]
tile_data['Year']=pd.to_numeric(tile_data['Year'],errors='coerce')
tile_data['Value']=pd.to_numeric(tile_data['Value'],errors='coerce')
tile_data=tile_data.dropna(subset=['Value'])
tile_data['LogValue']=np.log(tile_data['Value']) #for tile plots we want the data to be in log form
country_tile=tile_data[tile_data['Year']==2022].sort_values(by='Value',ascending=True)['Country'].tolist() #finding the highest co2 emissions at the end for each country
tile_data['Country']=pd.Categorical(tile_data['Country'],country_tile,ordered=True) #sort in the order of highest emissions at the end for the top countries
print(country_tile)
tile_data

import plotnine #plotnine is how we can work with ggplot in python!
from plotnine import *
tile_pic=ggplot(tile_data,aes(x='Year',y='Country',fill='LogValue'))+ geom_tile()+ scale_fill_gradient("pink", "purple")+labs(title = "Top 10 CO2 Emission-producing Countries",
       subtitle = "Ordered by Emissions Produced in 2022",
       fill = "Ln(CO2 Emissions (Metric Tonnes))")+theme(legend_position='bottom')

#similar to the case study but i just picked my own gradient and made sure to change the legend position for clarity

streamlit.pyplot(ggplot.draw(tile_pic)) 

tile_pic.save("tile_plot.png",dpi=300)

facet_data=final[final['Indicator'].isin(['Emissions','GDP','Energy Use'])]
facet_data['Year']=pd.to_numeric(facet_data['Year'],errors='coerce')
facet_data['Value']=pd.to_numeric(facet_data['Value'],errors='coerce')
facet_data=facet_data.dropna(subset=['Value'])
facet_data

#ggplot(facet_data, aes(x = 'Year', y = 'Value', group = 'Country')) + geom_line() + facet_grid('Indicator ~ Region', scales = "free_y")+labs(title = "Distribution of Indicators by Year and Value", y = "Indicator Value")



scatter_data=final[final['Indicator'].isin(['Emissions','Temperature'])]
scatter_data=scatter_data[scatter_data['Region']=='United States']
scatter_data=scatter_data[scatter_data['Year']<=2022]
scatter_data=scatter_data[scatter_data['Year']>=1980]
scatter_data['Year']=pd.to_numeric(scatter_data['Year'],errors='coerce')
scatter_data['Value']=pd.to_numeric(scatter_data['Value'],errors='coerce')
scatter_data=scatter_data.dropna(subset=['Value'])
scatter_data #we are now setting the years and the country just to us for the scatter plot data

#!pip install -q scikit-misc #this is so that we can use lowess like used in R!
co2_temp_facet=ggplot(scatter_data, aes(x = 'Year', y = 'Value')) + geom_point() + geom_smooth(method = "loess", se = False)+facet_wrap('~Label', scales='free_y', ncol=1)+labs(title='US Emissions and Temperatures (1980-2022)')
fig = ggplot.draw(co2_temp_facet)
streamlit.pyplot(fig)
fig.savefig("co2_temp_facet.png", dpi=300)
plt.close(fig)

facet_wide=scatter_data.pivot_table(index=['Year','Region'],columns='Indicator',values='Value',aggfunc='mean').reset_index()
facet_wide['Temperature'].dtype
#facet_wide

#now we plot emissions vs temp and use a linear regression estimate
ggplot(facet_wide, aes(x = 'Emissions', y = 'Temperature')) + geom_point() + geom_smooth(method = "lm", se = False)+labs(title='US Emissions and Temperature (1980-2022)')

"""# **Data Analysis**"""

#emissions info
print('mean of emissions: ',facet_wide['Emissions'].mean(),'  std of emissions: ',facet_wide['Emissions'].std())
print('mean of temperature: ',facet_wide['Temperature'].mean(),'  std of temperature: ',facet_wide['Temperature'].std())

#correlation coefficients
print('correlation coefficient: ',facet_wide['Emissions'].corr(facet_wide['Temperature']))

from sklearn.preprocessing import StandardScaler #simplest way of scaling the data

scaler=StandardScaler()
facet_wide[['Emissions','Temperature']]=scaler.fit_transform(facet_wide[['Emissions','Temperature']])
scaled_emissions_temp=ggplot(facet_wide,aes(x='Emissions',y='Temperature'))+geom_point()+geom_smooth(method='lm',se=False)+theme_linedraw()+labs(title='US Emissions and Temperature (1980-2022)',subtitle='Scaled Version')
display(scaled_emissions_temp)
scaled_emissions_temp.save("scaled_emissions_temp.png",dpi=300)

#!pip install pillow #this was just so that the pngs would populate nicely



"""# **the main questions**
1. global co2 emissions have increased over time. the us has increased significantly, but it's still not the highest compared to other countries
2. yes they are!!
"""
